import streamlit as st
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# í•™ìŠµëœ ëª¨ë¸ ìœ„ì¹˜, ì£¼ì†ŒëŠ” ì„¸ì…˜(ëŸ°í„°ì„) ë‹¤ì‹œ ì‹œì‘ë  ë•Œë§ˆë‹¤ ë§¤ë²ˆ ë‹¬ë¼ì§
model_path = "/content/results/checkpoint-639"

model = AutoModelForSequenceClassification.from_pretrained(model_path)


# -----------------------------
# 1) ëª¨ë¸ ë¡œë“œ
# -----------------------------
# model_path = "./results/checkpoint-final"  # í•™ìŠµëœ ëª¨ë¸ ìœ„ì¹˜


model_name = "beomi/KcELECTRA-base-v2022"

tokenizer = AutoTokenizer.from_pretrained(model_name)
# model = AutoModelForSequenceClassification.from_pretrained(model_path)

device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)
model.eval()

# -----------------------------
# 2) Streamlit UI êµ¬ì„±
# -----------------------------
st.title("ğŸ§  AI ê¸°ë°˜ ëŒ“ê¸€ íŒë³„ê¸°")
st.write("ì…ë ¥í•œ ëŒ“ê¸€ì´ **ì§„ì§œì¸ì§€**, **AIê°€ ìƒì„±í•œ ê°€ì§œì¸ì§€** í™•ë¥ ê³¼ í•¨ê»˜ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.")

# session_stateë¡œ ìƒˆë¡œê³ ì¹¨ ì „ê¹Œì§€ ê¸°ë¡ ìœ ì§€
if "history" not in st.session_state:
    st.session_state.history = []

# -----------------------------
# 3) ëŒ“ê¸€ ì…ë ¥ì°½
# -----------------------------
user_input = st.text_input("ëŒ“ê¸€ì„ ì…ë ¥í•˜ì„¸ìš”:", "")

# -----------------------------
# 4) ëŒ“ê¸€ íŒë³„ í•¨ìˆ˜
# -----------------------------
def predict(text):
    inputs = tokenizer(
        text,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=128
    ).to(device)

    with torch.no_grad():
        outputs = model(**inputs)

    logits = outputs.logits
    probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]

    return probs  # [fake_prob, real_prob]

# -----------------------------
# 5) ì˜ˆì¸¡ ì‹¤í–‰
# -----------------------------
if user_input:
    probs = predict(user_input)
    fake_prob = probs[0]
    real_prob = probs[1]

    st.subheader("ğŸ“Š íŒë³„ ê²°ê³¼")
    st.write(f"âœ” **ì§„ì§œ ëŒ“ê¸€ì¼ í™•ë¥ :** {real_prob*100:.2f}%")
    st.write(f"âœ” **AI ìƒì„±(ê°€ì§œ) ëŒ“ê¸€ì¼ í™•ë¥ :** {fake_prob*100:.2f}%")

    # ê°„ë‹¨í•œ ì„¤ëª… ì œê³µ (ì¡°ê±´3)
    st.subheader("ğŸ“ íŒë³„ ì´ìœ (ê°„ë‹¨ ì„¤ëª…)")
    if real_prob > fake_prob:
        st.write("ì´ ëŒ“ê¸€ì€ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ê³¼ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆì–´ ì§„ì§œì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")
    else:
        st.write("ì´ ëŒ“ê¸€ì€ ë°˜ë³µì ì´ê±°ë‚˜ ì „í˜•ì ì¸ ë¬¸ì¥ íŒ¨í„´ì„ ì‚¬ìš©í•´ AI ìƒì„± ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")

    # ì…ë ¥ ê¸°ë¡ ì €ì¥
    st.session_state.history.append({
        "text": user_input,
        "fake": fake_prob,
        "real": real_prob
    })

# -----------------------------
# 6) ê¸°ë¡ ë³´ì—¬ì£¼ê¸°
# -----------------------------
st.subheader("ğŸ—‚ ì…ë ¥í–ˆë˜ ëŒ“ê¸€ ê¸°ë¡ (ìƒˆë¡œê³ ì¹¨ ì „ê¹Œì§€ ìœ ì§€)")
for item in st.session_state.history:
    st.write(f"- {item['text']} â†’ ì§„ì§œ:{item['real']:.2f}, ê°€ì§œ:{item['fake']:.2f}")
